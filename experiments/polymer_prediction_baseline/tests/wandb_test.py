#!/usr/bin/env python3
"""
NeurIPS Open Polymer Prediction 2025 - WandBå®Ÿé¨“ç®¡ç†ãƒ†ã‚¹ãƒˆ
WandBã‚’ä½¿ã£ãŸå®Ÿé¨“è¿½è·¡ã¨ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
import warnings
import numpy as np
import pandas as pd
import wandb
from pathlib import Path
from datetime import datetime

# MLé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb

warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
DATA_DIR = PROJECT_ROOT / "data" / "raw"
EXPERIMENTS_DIR = PROJECT_ROOT / "experiments" / "polymer_prediction_baseline"

print(f"ğŸš€ WandBå®Ÿé¨“ç®¡ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
print(f"ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {PROJECT_ROOT}")

# RDKitåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
try:
    from rdkit import Chem
    from rdkit.Chem import Descriptors
    rdkit_available = True
    print("âœ… RDKitåˆ©ç”¨å¯èƒ½ - é«˜ç²¾åº¦åˆ†å­ç‰¹å¾´é‡ã‚’ä½¿ç”¨")
except ImportError:
    rdkit_available = False
    print("âš ï¸  RDKitåˆ©ç”¨ä¸å¯ - åŸºæœ¬SMILESç‰¹å¾´é‡ã‚’ä½¿ç”¨")

def load_local_data():
    """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    print("ğŸ“‚ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    train_path = DATA_DIR / "train.csv"
    test_path = DATA_DIR / "test.csv"
    sample_submission_path = DATA_DIR / "sample_submission.csv"
    
    if not all([train_path.exists(), test_path.exists(), sample_submission_path.exists()]):
        raise FileNotFoundError("å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    train = pd.read_csv(train_path)
    test = pd.read_csv(test_path)
    submission = pd.read_csv(sample_submission_path)
    
    print(f"âœ… è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {train.shape}")
    print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {test.shape}")
    
    return train, test, submission

def basic_smiles_features(smiles):
    """åŸºæœ¬çš„ãªSMILESç‰¹å¾´é‡"""
    if pd.isna(smiles) or smiles == '':
        return [0] * 10
    
    features = [
        len(smiles),                    # SMILESæ–‡å­—åˆ—é•·
        smiles.count('C'),             # ç‚­ç´ æ•°
        smiles.count('N'),             # çª’ç´ æ•°
        smiles.count('O'),             # é…¸ç´ æ•°
        smiles.count('S'),             # ç¡«é»„æ•°
        smiles.count('='),             # äºŒé‡çµåˆæ•°
        smiles.count('#'),             # ä¸‰é‡çµåˆæ•°
        smiles.count('('),             # åˆ†å²æ•°
        smiles.count('['),             # ç‰¹æ®ŠåŸå­æ•°
        smiles.count('@'),             # ã‚­ãƒ©ãƒ«ä¸­å¿ƒæ•°
    ]
    return features

def quick_feature_engineering(df):
    """ã‚¯ã‚¤ãƒƒã‚¯ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
    print("ğŸ§¬ åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
    
    # SMILESåŸºæœ¬ç‰¹å¾´é‡
    smiles_features = []
    for smiles in df['SMILES']:
        features = basic_smiles_features(smiles)
        smiles_features.append(features)
    
    feature_names = [
        'smiles_length', 'carbon_count', 'nitrogen_count', 'oxygen_count', 'sulfur_count',
        'double_bond_count', 'triple_bond_count', 'branch_count', 'special_atom_count', 'chiral_count'
    ]
    
    features_df = pd.DataFrame(smiles_features, columns=feature_names)
    
    print(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {features_df.shape[1]}å€‹ã®ç‰¹å¾´é‡")
    return features_df

def wandb_test():
    """WandBå®Ÿé¨“ç®¡ç†ãƒ†ã‚¹ãƒˆ"""
    start_time = time.time()
    
    # WandBåˆæœŸåŒ–ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆï¼‰
    print("ğŸ”§ WandBåˆæœŸåŒ–ä¸­...")
    try:
        # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–ï¼ˆãƒ­ã‚°ã‚¤ãƒ³ãªã—ã§ãƒ†ã‚¹ãƒˆå¯èƒ½ï¼‰
        run = wandb.init(
            project="neurips-polymer-prediction-test",
            name=f"baseline_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            mode="offline",  # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆ
            config={
                "model_type": "random_forest",
                "n_estimators": 10,
                "max_depth": 5,
                "random_state": 42,
                "rdkit_available": rdkit_available,
                "feature_count": 10
            }
        )
        print("âœ… WandBåˆæœŸåŒ–æˆåŠŸï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼‰")
        wandb_available = True
    except Exception as e:
        print(f"âš ï¸  WandBåˆæœŸåŒ–å¤±æ•—: {e}")
        print("ğŸ“ WandBãªã—ã§ãƒ†ã‚¹ãƒˆç¶™ç¶š")
        wandb_available = False
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    train, test, submission = load_local_data()
    
    # ç‰¹å¾´é‡ç”Ÿæˆ
    train_features = quick_feature_engineering(train)
    test_features = quick_feature_engineering(test)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’WandBã«è¨˜éŒ²
    if wandb_available:
        wandb.log({
            "data/train_size": len(train),
            "data/test_size": len(test),
            "data/feature_count": train_features.shape[1]
        })
    
    # ç°¡å˜ãªãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆè¤‡æ•°ã®ç‰¹æ€§ã§ãƒ†ã‚¹ãƒˆï¼‰
    target_cols = ['Tg', 'Tm', 'Density']  # è¤‡æ•°ã®ç‰¹æ€§ã‚’ãƒ†ã‚¹ãƒˆ
    results = {}
    
    for target_col in target_cols:
        if target_col in train.columns:
            print(f"ğŸ¤– {target_col}ç”¨ã®ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...")
            
            # æ¬ æå€¤é™¤å»
            valid_mask = ~train[target_col].isna()
            X_valid = train_features[valid_mask]
            y_valid = train[target_col][valid_mask]
            
            print(f"âœ… {target_col} æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿: {len(X_valid)}ä»¶")
            
            if len(X_valid) > 10:  # æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿å®Ÿè¡Œ
                # ç°¡å˜ãªRandomForestãƒ¢ãƒ‡ãƒ«
                model = RandomForestRegressor(n_estimators=10, max_depth=5, random_state=42)
                
                # 2-Fold CVã§MAEè¨ˆç®—
                kf = KFold(n_splits=2, shuffle=True, random_state=42)
                cv_scores = []
                
                for fold, (train_idx, val_idx) in enumerate(kf.split(X_valid)):
                    X_train_fold = X_valid.iloc[train_idx]
                    X_val_fold = X_valid.iloc[val_idx]
                    y_train_fold = y_valid.iloc[train_idx]
                    y_val_fold = y_valid.iloc[val_idx]
                    
                    model.fit(X_train_fold, y_train_fold)
                    y_pred = model.predict(X_val_fold)
                    mae = mean_absolute_error(y_val_fold, y_pred)
                    cv_scores.append(mae)
                    
                    print(f"  ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ {fold+1} MAE: {mae:.3f}")
                    
                    # WandBã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰çµæœã‚’è¨˜éŒ²
                    if wandb_available:
                        wandb.log({
                            f"{target_col}/fold_{fold+1}_mae": mae,
                            f"{target_col}/fold": fold+1
                        })
                
                avg_mae = np.mean(cv_scores)
                results[target_col] = avg_mae
                
                # å…¨ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´
                model.fit(X_valid, y_valid)
                
                # ãƒ†ã‚¹ãƒˆäºˆæ¸¬
                test_pred = model.predict(test_features)
                
                # çµæœè¡¨ç¤º
                print(f"âœ… {target_col} CV MAE: {avg_mae:.3f}")
                print(f"âœ… {target_col} äºˆæ¸¬ç¯„å›²: {np.min(test_pred):.2f} - {np.max(test_pred):.2f}")
                
                # WandBã«æœ€çµ‚çµæœã‚’è¨˜éŒ²
                if wandb_available:
                    wandb.log({
                        f"{target_col}/cv_mae": avg_mae,
                        f"{target_col}/pred_mean": np.mean(test_pred),
                        f"{target_col}/pred_std": np.std(test_pred),
                        f"{target_col}/pred_min": np.min(test_pred),
                        f"{target_col}/pred_max": np.max(test_pred)
                    })
            else:
                print(f"âš ï¸  {target_col} ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
    
    elapsed_time = time.time() - start_time
    
    # å®Ÿé¨“ã‚µãƒãƒªãƒ¼
    print(f"\nğŸ“Š å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼:")
    for target, mae in results.items():
        print(f"  {target}: CV MAE = {mae:.3f}")
    
    # WandBã«ç·åˆçµæœã‚’è¨˜éŒ²
    if wandb_available:
        wandb.log({
            "experiment/elapsed_time": elapsed_time,
            "experiment/target_count": len(results),
            "experiment/avg_mae": np.mean(list(results.values())) if results else 0
        })
        
        # å®Ÿé¨“çµ‚äº†
        wandb.finish()
        print("âœ… WandBå®Ÿé¨“è¨˜éŒ²å®Œäº†")
    
    print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f} ç§’")
    print("ğŸ‰ WandBå®Ÿé¨“ç®¡ç†ãƒ†ã‚¹ãƒˆå®Œäº†!")
    
    return results

if __name__ == "__main__":
    results = wandb_test()
    print(f"\nğŸ¯ æœ€çµ‚çµæœ: {len(results)}å€‹ã®ç‰¹æ€§ã§å®Ÿé¨“å®Œäº†")